{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ligand receptor analysis\n",
    "\n",
    "In this analysis we are going to use CellPhoneDB (>= v3) to analyse interactions between (1) fibroblas subpopulations and (2) fibroblast subpopulations with the rest of populations. To save time, we are going to do (2) and, then, extract (1) from it. We are goin to run the analysis on each dataset, and then do a general combination of interactions to get a general frame of interactions that occur across datasets.\n",
    "\n",
    "**YOU NEED TO RUN NOTEBOOK 4H FIRST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import scanpy.external as sce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import triku as tk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.sparse as spr\n",
    "import matplotlib.cm as cm\n",
    "import networkx as nx\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# local imports and imports from other notebooks\n",
    "from cellassign import assign_cats\n",
    "from fb_functions import make_gene_scoring_with_expr, plot_score_graph, plot_UMAPS_gene, plot_adata_cluster_properties\n",
    "%store -r dict_colors\n",
    "%store -r seed\n",
    "%store -r magma\n",
    "%store -r data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r dict_make_gene_scoring_robust\n",
    "%store -r dict_make_gene_scoring_axis_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 120\n",
    "pd.options.display.float_format = \"{:,.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def join_fbs_adatas(adata_full, adata_fb):\n",
    "    cell_types = adata_full.obs['assigned_cats'].copy().astype(str)\n",
    "    intersect_idx = np.intersect1d(adata_fb.obs_names, adata_full.obs_names)\n",
    "    cell_types[intersect_idx] = [f'fibro_{i}' for i in adata_fb[intersect_idx].obs['cluster']]\n",
    "    adata_full.obs['full_cell_type'] = cell_types.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anndata loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_adatas_fb, list_adatas_full = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ahlers_2022_dir = data_dir + '/ahlers_2022'\n",
    "ahlers_2022_young_human_fb = sc.read(ahlers_2022_dir + '/ahlers_2022_young_human_fb_robust.h5')\n",
    "ahlers_2022_young_human = sc.read(ahlers_2022_dir + '/ahlers_2022_young_human_processed.h5')\n",
    "join_fbs_adatas(ahlers_2022_young_human, ahlers_2022_young_human_fb)\n",
    "list_adatas_fb.append(ahlers_2022_young_human_fb); list_adatas_full.append(ahlers_2022_young_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boothby_2021_dir = data_dir + '/boothby_2021'\n",
    "boothby_2021_ctrl_human_fb = sc.read(boothby_2021_dir + '/boothby_2021_ctrl_human_fb_robust.h5')\n",
    "boothby_2021_ctrl_human = sc.read(boothby_2021_dir + '/boothby_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(boothby_2021_ctrl_human, boothby_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(boothby_2021_ctrl_human_fb); list_adatas_full.append(boothby_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deng_2021_dir = data_dir + '/deng_2021'\n",
    "deng_2021_scar_fb = sc.read(deng_2021_dir + '/deng_2021_scar_fb_robust.h5')\n",
    "deng_2021_scar = sc.read(deng_2021_dir + '/deng_2021_scar_processed.h5')\n",
    "join_fbs_adatas(deng_2021_scar, deng_2021_scar_fb)\n",
    "list_adatas_fb.append(deng_2021_scar_fb); list_adatas_full.append(deng_2021_scar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gao_2021_dir = data_dir + '/gao_2021'\n",
    "gao_2021_ctrl_human_fb = sc.read(gao_2021_dir + '/gao_2021_ctrl_human_fb_robust.h5')\n",
    "gao_2021_ctrl_human = sc.read(gao_2021_dir + '/gao_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(gao_2021_ctrl_human, gao_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(gao_2021_ctrl_human_fb); list_adatas_full.append(gao_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gaydosik_2020_dir = data_dir + '/gaydosik_2020'\n",
    "gaydosik_2020_ctrl_human_fb = sc.read(gaydosik_2020_dir + '/gaydosik_2020_ctrl_human_fb_robust.h5')\n",
    "gaydosik_2020_ctrl_human = sc.read(gaydosik_2020_dir + '/gaydosik_2020_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(gaydosik_2020_ctrl_human, gaydosik_2020_ctrl_human_fb)\n",
    "list_adatas_fb.append(gaydosik_2020_ctrl_human_fb); list_adatas_full.append(gaydosik_2020_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gur_2022_dir = data_dir + '/gur_2022'\n",
    "gur_2022_ctrl_human_fb = sc.read(gur_2022_dir + '/gur_2022_ctrl_human_fb_robust.h5')\n",
    "gur_2022_ctrl_human = sc.read(gur_2022_dir + '/gur_2022_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(gur_2022_ctrl_human, gur_2022_ctrl_human_fb)\n",
    "list_adatas_fb.append(gur_2022_ctrl_human_fb); list_adatas_full.append(gur_2022_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "he_2020_dir = data_dir + '/He_2020'\n",
    "he_2020_ctrl_human_fb = sc.read(he_2020_dir + '/he_2020_ctrl_human_fb_robust.h5')\n",
    "he_2020_ctrl_human = sc.read(he_2020_dir + '/he_2020_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(he_2020_ctrl_human, he_2020_ctrl_human_fb)\n",
    "list_adatas_fb.append(he_2020_ctrl_human_fb); list_adatas_full.append(he_2020_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hughes_2020_dir = data_dir + '/hughes_2020'\n",
    "hughes_2020_ctrl_human_fb = sc.read(hughes_2020_dir + '/hughes_2020_ctrl_human_fb_robust.h5')\n",
    "hughes_2020_ctrl_human = sc.read(hughes_2020_dir + '/hughes_2020_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(hughes_2020_ctrl_human, hughes_2020_ctrl_human_fb)\n",
    "list_adatas_fb.append(hughes_2020_ctrl_human_fb); list_adatas_full.append(hughes_2020_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kim_2020_dir = data_dir + '/Kim_2020'\n",
    "kim_2020_ctrl_human_fb = sc.read(kim_2020_dir + '/kim_2020_ctrl_human_fb_robust.h5')\n",
    "kim_2020_ctrl_human = sc.read(kim_2020_dir + '/kim_2020_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(kim_2020_ctrl_human, kim_2020_ctrl_human_fb)\n",
    "list_adatas_fb.append(kim_2020_ctrl_human_fb); list_adatas_full.append(kim_2020_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liu_2021_dir = data_dir + '/liu_2021'\n",
    "liu_2021_ctrl_human_fb = sc.read(liu_2021_dir + '/liu_2021_ctrl_human_fb_robust.h5')\n",
    "liu_2021_ctrl_human = sc.read(liu_2021_dir + '/liu_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(liu_2021_ctrl_human, liu_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(liu_2021_ctrl_human_fb); list_adatas_full.append(liu_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mariottoni_2021_dir = data_dir + '/mariottoni_2021'\n",
    "mariottoni_2021_ctrl_human_fb = sc.read(mariottoni_2021_dir + '/mariottoni_2021_ctrl_human_fb_robust.h5')\n",
    "mariottoni_2021_ctrl_human = sc.read(mariottoni_2021_dir + '/mariottoni_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(mariottoni_2021_ctrl_human, mariottoni_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(mariottoni_2021_ctrl_human_fb); list_adatas_full.append(mariottoni_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mirizio_2020_dir = data_dir + '/mirizio_2020'\n",
    "mirizio_2020_scl_human_fb = sc.read(mirizio_2020_dir + '/mirizio_2020_scl_human_fb_robust.h5')\n",
    "mirizio_2020_scl_human = sc.read(mirizio_2020_dir + '/mirizio_2020_scl_human_processed.h5')\n",
    "join_fbs_adatas(mirizio_2020_scl_human, mirizio_2020_scl_human_fb)\n",
    "list_adatas_fb.append(mirizio_2020_scl_human_fb); list_adatas_full.append(mirizio_2020_scl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reynolds_2021_dir = data_dir + '/reynolds_2021'\n",
    "reynolds_2021_ctrl_human_fb = sc.read(reynolds_2021_dir + '/reynolds_2021_ctrl_human_fb_robust.h5')\n",
    "# Dataset with the rest of cells is not available. It can be used but since the dataset doesn't have good quality, is not fully relevant.\n",
    "reynolds_2021_ctrl_human_fb.obs['full_cell_type'] = [f'fibro_{i}' for i in reynolds_2021_ctrl_human_fb.obs['cluster']]\n",
    "reynolds_2021_ctrl_human_fb.obs['full_cell_type'] = reynolds_2021_ctrl_human_fb.obs['full_cell_type'].astype('category')\n",
    "list_adatas_fb.append(reynolds_2021_ctrl_human_fb); list_adatas_full.append(reynolds_2021_ctrl_human_fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rindler_2021_dir = data_dir + '/rindler_2021'\n",
    "rindler_2021_ctrl_human_fb = sc.read(rindler_2021_dir + '/rindler_2021_ctrl_human_fb_robust.h5')\n",
    "rindler_2021_ctrl_human = sc.read(rindler_2021_dir + '/rindler_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(rindler_2021_ctrl_human, rindler_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(rindler_2021_ctrl_human_fb); list_adatas_full.append(rindler_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sole_2020_dir = data_dir + '/Sole-Boldo_2020'\n",
    "sole_2020_young_human_fb = sc.read(sole_2020_dir + '/sole_2020_young_human_fb_robust.h5')\n",
    "sole_2020_young_human = sc.read(sole_2020_dir + '/sole_2020_young_human_processed.h5')\n",
    "join_fbs_adatas(sole_2020_young_human, sole_2020_young_human_fb)\n",
    "list_adatas_fb.append(sole_2020_young_human_fb); list_adatas_full.append(sole_2020_young_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabib_2018_dir = data_dir + '/Tabib_2018'\n",
    "tabib_2018_ctrl_human_fb = sc.read(tabib_2018_dir + '/tabib_2018_ctrl_human_fb_robust.h5')\n",
    "tabib_2018_ctrl_human = sc.read(tabib_2018_dir + '/tabib_2018_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(tabib_2018_ctrl_human, tabib_2018_ctrl_human_fb)\n",
    "list_adatas_fb.append(tabib_2018_ctrl_human_fb); list_adatas_full.append(tabib_2018_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabib_2021_dir = data_dir + '/Tabib_2021'\n",
    "tabib_2021_ctrl_human_fb = sc.read(tabib_2021_dir + '/tabib_2021_ctrl_human_fb_robust.h5')\n",
    "tabib_2021_ctrl_human = sc.read(tabib_2021_dir + '/tabib_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(tabib_2021_ctrl_human, tabib_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(tabib_2021_ctrl_human_fb); list_adatas_full.append(tabib_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theo_2020_dir = data_dir + '/Theocharidis_2020/'\n",
    "theo_2020_ctrl_human_dm_fb = sc.read(theo_2020_dir + '/theo_2020_ctrl_human_dm_fb_robust.h5')\n",
    "theo_2020_ctrl_human_dm = sc.read(theo_2020_dir + '/theo_2020_ctrl_human_dm_processed.h5')\n",
    "join_fbs_adatas(theo_2020_ctrl_human_dm, theo_2020_ctrl_human_dm_fb)\n",
    "list_adatas_fb.append(theo_2020_ctrl_human_dm_fb); list_adatas_full.append(theo_2020_ctrl_human_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theo_2021_dir = data_dir + '/Theocharidis_2021/'\n",
    "theo_2021_ctrl_human_fb = sc.read(theo_2021_dir + '/theo_2021_ctrl_human_fb_robust.h5')\n",
    "theo_2021_ctrl_human = sc.read(theo_2021_dir + '/theo_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(theo_2021_ctrl_human, theo_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(theo_2021_ctrl_human_fb); list_adatas_full.append(theo_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vors_2020_dir = data_dir + '/Vorstandlechner_2020'\n",
    "vors_2020_ctrl_human_fb = sc.read(vors_2020_dir + '/vors_2020_ctrl_human_fb_robust.h5')\n",
    "vors_2020_ctrl_human = sc.read(vors_2020_dir + '/vors_2020_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(vors_2020_ctrl_human, vors_2020_ctrl_human_fb)\n",
    "list_adatas_fb.append(vors_2020_ctrl_human_fb); list_adatas_full.append(vors_2020_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vors_2021_dir = data_dir + '/Vorstandlechner_2021'\n",
    "vors_2021_ctrl_human_fb = sc.read(vors_2021_dir + '/vors_2021_ctrl_human_fb_robust.h5')\n",
    "vors_2021_ctrl_human = sc.read(vors_2021_dir + '/vors_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(vors_2021_ctrl_human, vors_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(vors_2021_ctrl_human_fb); list_adatas_full.append(vors_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xu_2021_dir = data_dir + '/xu_2021'\n",
    "xu_2021_ctrl_human_fb = sc.read(xu_2021_dir + '/xu_2021_ctrl_human_fb_robust.h5')\n",
    "xu_2021_ctrl_human = sc.read(xu_2021_dir + '/xu_2021_ctrl_human_processed.h5')\n",
    "join_fbs_adatas(xu_2021_ctrl_human, xu_2021_ctrl_human_fb)\n",
    "list_adatas_fb.append(xu_2021_ctrl_human_fb); list_adatas_full.append(xu_2021_ctrl_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_names = [str(adata.obs['Author'].iloc[0]) + ' ' + str(int(adata.obs['Year'].iloc[0])) + ' human' for adata in list_adatas_fb ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a custom db\n",
    "We are going to create a custom database with additional LR interactions from other sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('results/CellPhoneDB/dbsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cellphonedb database generate  --result-path results/CellPhoneDB/dbsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create from biomart a dataset of mouse info with columns \"UniProtKB Gene Name symbol\" and \"UniProtKB Gene Name ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proteins = pd.read_csv('results/CellPhoneDB/dbsample/protein_generated.csv')\n",
    "df_genes = pd.read_csv('results/CellPhoneDB/dbsample/gene_generated.csv')\n",
    "df_interactions = pd.read_csv('results/CellPhoneDB/dbsample/interaction_input.csv')\n",
    "df_biomart = pd.read_csv('data/mart_export.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify gene_generated to gene_inpuit by adding genes in mouse\n",
    "df_biomart.drop_duplicates(subset='UniProtKB Gene Name symbol', keep='last', ignore_index=True, inplace=True)\n",
    "df_biomart.index += len(df_genes)\n",
    "df_biomart.columns = ['gene_name', 'hgnc_symbol', 'uniprot', 'ensembl']\n",
    "df_genes = df_genes.append(df_biomart)\n",
    "\n",
    "df_genes.to_csv('results/CellPhoneDB/dbsample/gene_input_custom.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify protein_generated to protein_inpuit by adding proteins in mouse\n",
    "df_biomart.drop_duplicates(subset='uniprot', keep='last', ignore_index=True, inplace=True)\n",
    "df_biomart.index += len(df_proteins)\n",
    "df_biomart = df_biomart[['gene_name', 'uniprot']]\n",
    "df_biomart.columns = ['protein_name', 'uniprot']\n",
    "df_biomart['protein_name'] = [str(i).upper() + '_MOUSE' for i in df_biomart['protein_name']] \n",
    "df_proteins = df_proteins.append(df_biomart)\n",
    "\n",
    "df_proteins.iloc[df_biomart.index, [2, 3 ,4]] = True # set transmembrane, peripheral and secreted to True\n",
    "\n",
    "df_proteins.to_csv('results/CellPhoneDB/dbsample/protein_input_custom.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download mouse and human pairs from http://tcm.zju.edu.cn/celltalkdb/download.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_proteins_uniprot = dict(zip(df_proteins['protein_name'].values, df_proteins['uniprot'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_new_pairs_celltalkdb = pd.read_csv('data/human_lr_pair.txt', sep='\\t')\n",
    "mouse_new_pairs_celltalkdb = pd.read_csv('data/mouse_lr_pair.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_new_pairs_celltalkdb = human_new_pairs_celltalkdb[['ligand_gene_symbol', 'receptor_gene_symbol']]\n",
    "human_new_pairs_celltalkdb.columns = ['protein_name_a', 'protein_name_b']\n",
    "human_new_pairs_celltalkdb += '_HUMAN'\n",
    "human_new_pairs_celltalkdb['partner_a'] = [dict_proteins_uniprot[i] if i in dict_proteins_uniprot else np.NaN for i in human_new_pairs_celltalkdb['protein_name_a']]\n",
    "human_new_pairs_celltalkdb['partner_b'] = [dict_proteins_uniprot[i] if i in dict_proteins_uniprot else np.NaN for i in human_new_pairs_celltalkdb['protein_name_b']]\n",
    "human_new_pairs_celltalkdb = human_new_pairs_celltalkdb.dropna().reset_index(drop=True)\n",
    "human_new_pairs_celltalkdb.index += len(df_interactions)\n",
    "df_interactions = df_interactions.append(human_new_pairs_celltalkdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mouse_new_pairs_celltalkdb = mouse_new_pairs_celltalkdb[['ligand_gene_symbol', 'receptor_gene_symbol']]\n",
    "mouse_new_pairs_celltalkdb.columns = ['protein_name_a', 'protein_name_b']\n",
    "mouse_new_pairs_celltalkdb = mouse_new_pairs_celltalkdb.apply(lambda x: x.astype(str).str.upper()) + '_MOUSE'\n",
    "mouse_new_pairs_celltalkdb['partner_a'] = [dict_proteins_uniprot[i] if i in dict_proteins_uniprot else np.NaN for i in mouse_new_pairs_celltalkdb['protein_name_a']]\n",
    "mouse_new_pairs_celltalkdb['partner_b'] = [dict_proteins_uniprot[i] if i in dict_proteins_uniprot else np.NaN for i in mouse_new_pairs_celltalkdb['protein_name_b']]\n",
    "mouse_new_pairs_celltalkdb = mouse_new_pairs_celltalkdb.dropna().reset_index(drop=True)\n",
    "mouse_new_pairs_celltalkdb.index += len(df_interactions)\n",
    "df_interactions = df_interactions.append(mouse_new_pairs_celltalkdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_interactions['annotation_strategy'] = 'curated'\n",
    "df_interactions.to_csv('results/CellPhoneDB/dbsample/interaction_input_custom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cellphonedb database generate  --result-path results/CellPhoneDB/dbsample --user-interactions-only \n",
    "--user-gene results/CellPhoneDB/dbsample/gene_input_custom.csv --user-protein results/CellPhoneDB/dbsample/protein_input_custom.csv \n",
    "--user-interactions results/CellPhoneDB/dbsample/interaction_input_custom.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = [i for i in os.listdir('results/CellPhoneDB/dbsample') if i[-2:] == 'db' ]\n",
    "os.rename(f'results/CellPhoneDB/dbsample/{list_files[-1]}', 'results/CellPhoneDB/dbsample/customdb.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running CellPhoneDB on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cellphone_dir = f'results/CellPhoneDB/'\n",
    "os.makedirs(cellphone_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for adata, name in zip(list_adatas_full, list_names):\n",
    "    print(name)\n",
    "    name_str = name.lower().replace(' ', '_')\n",
    "    os.makedirs(cellphone_dir + name_str, exist_ok=True)\n",
    "\n",
    "    df_meta = pd.DataFrame(data={'Cell':list(adata.obs.index), 'cell_type':[ i for i in adata.obs['full_cell_type']]})\n",
    "    df_meta.set_index('Cell', inplace=True)\n",
    "    df_meta.to_csv(f'{cellphone_dir}/{name_str}/meta.tsv', sep = '\\t')\n",
    "    \n",
    "    df_counts = pd.DataFrame(adata.X.toarray()).transpose()\n",
    "    df_counts.index = adata.var_names\n",
    "    df_counts.columns = adata.obs_names\n",
    "\n",
    "    df_counts.to_csv(f'{cellphone_dir}/{name_str}/{name_str}.txt', sep='\\t')\n",
    "    \n",
    "    !cellphonedb method statistical_analysis  \\\n",
    "    {cellphone_dir}/{name_str}/meta.tsv  \\\n",
    "    {cellphone_dir}/{name_str}/{name_str}.txt \\\n",
    "    --threshold 0.1 --threads 40 \\\n",
    "    --output-path={cellphone_dir}{name_str} --counts-data hgnc_symbol \\\n",
    "    --database results/CellPhoneDB/dbsample/customdb.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_unstack = pd.DataFrame(columns = ['dataset', 'gene_A', 'gene_B', 'pair_A', 'pair_B', 'value'])\n",
    "df_unstack_fibros = pd.DataFrame(columns = df_unstack.columns)\n",
    "\n",
    "\n",
    "for list_name in list_names:\n",
    "    name, year = list_name.split(' ')[0], list_name.split(' ')[1]\n",
    "\n",
    "    df = pd.read_csv(f'results/CellPhoneDB/{name.lower()}_{year}_human/significant_means.txt', sep='\\t')\n",
    "\n",
    "    select_cols = [i for i in df.columns if 'fibro' in i]\n",
    "    select_idx = df[select_cols].dropna(how='all').index\n",
    "\n",
    "    df = df.loc[select_idx][list(df.columns[:12]) + select_cols]\n",
    "\n",
    "    df_unstack_dataset = pd.DataFrame({'dataset': [f'{name} {year}'] * len(select_cols) * len(df), \n",
    "                               'gene_A': np.repeat(df['gene_a'].tolist(), len(select_cols)), \n",
    "                               'gene_B': np.repeat(df['gene_b'].tolist(), len(select_cols)), \n",
    "                               'pair_A': [i.split('|')[0] for i in select_cols] * len(df), \n",
    "                               'pair_B': [i.split('|')[1] for i in select_cols] * len(df), \n",
    "                               'value': df[select_cols].values.ravel()})\n",
    "\n",
    "    df_unstack_dataset = df_unstack_dataset.dropna(subset = ['value'])\n",
    "    \n",
    "    df_unstack_fibros_dataset = df_unstack_dataset.loc[np.array(['fibro' in i for i in df_unstack_dataset['pair_A']]) & \n",
    "                                                       np.array(['fibro' in i for i in df_unstack_dataset['pair_B']])]\n",
    "    \n",
    "    \n",
    "    df_unstack = pd.concat([df_unstack, df_unstack_dataset], ignore_index=True, sort=False)\n",
    "    df_unstack_fibros = pd.concat([df_unstack_fibros, df_unstack_fibros_dataset], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting information between fibroblasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing \n",
    "\n",
    "df_processed = df_unstack_fibros\n",
    "%store -r dict_knee_markers\n",
    "\n",
    "# 1) Remove duplicates by all columns expect value. This is because if pair_A == pair_B in some cases the values are the same. \n",
    "# This produces problems later when counting datasets.\n",
    "\n",
    "pair_gene_cols = ['gene_A', 'gene_B', 'pair_A', 'pair_B']\n",
    "\n",
    "df_processed = df_processed.groupby(['dataset'] + pair_gene_cols, as_index=False).mean()\n",
    "\n",
    "\n",
    "\n",
    "# 2) We group the values. For the numeric values, we compute the median across cases. For string values, we join and count them. \n",
    "\n",
    "df_grouped = pd.DataFrame(index=df_processed.groupby(pair_gene_cols).sum().index)\n",
    "df_grouped['value'] = df_processed.groupby(pair_gene_cols).median()['value']\n",
    "df_grouped['dataset_list'] = df_processed.groupby(pair_gene_cols)['dataset'].apply(', '.join)\n",
    "df_grouped['dataset_count'] = df_processed.groupby(pair_gene_cols)['dataset'].count()\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# 3) We want to keep only the LR pairs that are consistentr among datasets. Therefore, we will establish a threshold of datasets in which \n",
    "# that interaction appears. Because some clusters are specific of fewer datasets, we will consider the lower threshold a percentage (60-80%) of\n",
    "# the less frequent cluster\n",
    "\n",
    "# 3A) Create the dict with correspondence between clusters and counts\n",
    "list_clusters = []\n",
    "for adata in list_adatas_fb:\n",
    "    list_clusters += adata.obs['cluster_robust'].cat.categories.tolist()\n",
    "clusters, counts = np.unique(list_clusters, return_counts=True)\n",
    "dict_cluster_counts = dict(zip(clusters, counts))\n",
    "\n",
    "# 3B) Apply the dataset filter\n",
    "thres = 0.3\n",
    "\n",
    "pair_A_counts = [dict_cluster_counts[i[-2:]] if i[-2:] in dict_cluster_counts.keys() else 100 for i in df_grouped['pair_A'].values]\n",
    "pair_B_counts = [dict_cluster_counts[i[-2:]] if i[-2:] in dict_cluster_counts.keys() else 100 for i in df_grouped['pair_B'].values]\n",
    "min_pair_counts = [min(i, j) for i, j in zip(pair_A_counts, pair_B_counts)]\n",
    "\n",
    "mask_idx = df_grouped['dataset_count'] > np.array(min_pair_counts) * thres\n",
    "\n",
    "\n",
    "df_grouped = df_grouped.replace('nan', np.nan)\n",
    "df_masked = df_grouped.loc[mask_idx].dropna(subset=['gene_A', 'gene_B'], how='all').reset_index(drop=True)\n",
    "\n",
    "# 3C) Apply the gene filter: we are going to keep genes that are \"relevant\" markers. Other genes that appear as positive in CellPhoneDB tend to \n",
    "# be thorougly expressed and are not relevant\n",
    "pair_A_bool = [((pair[-2:] in dict_knee_markers.keys()) & (gene in dict_knee_markers.get(pair[-2:], []))) \n",
    "                 for gene, pair in zip(df_masked['gene_A'].values, df_masked['pair_A'].values)]\n",
    "pair_B_bool = [((pair[-2:] in dict_knee_markers.keys()) & (gene in dict_knee_markers.get(pair[-2:], []))) \n",
    "                 for gene, pair in zip(df_masked['gene_B'].values, df_masked['pair_B'].values)]\n",
    "\n",
    "mask_bool = np.array(pair_A_bool) & np.array(pair_B_bool)\n",
    "mask_bool.sum()\n",
    "\n",
    "df_masked_fibros = df_masked.loc[mask_bool].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "df_alias = df_masked_fibros.copy()\n",
    "cats = sorted(list(set(df_alias['pair_A']) | set(df_alias['pair_B'])))\n",
    "\n",
    "df_heatmap = pd.DataFrame(0, index=cats, columns=cats)\n",
    "\n",
    "\n",
    "for cat_A, cat_B in itl.combinations_with_replacement(cats, 2):\n",
    "    sub_df = df_alias[((df_alias['pair_A'] == cat_A) & (df_alias['pair_B'] == cat_B)) | \n",
    "                      ((df_alias['pair_A'] == cat_B) & (df_alias['pair_B'] == cat_A))].drop_duplicates(['gene_A', 'gene_B'])\n",
    "    df_heatmap.loc[cat_A, cat_B] = len(sub_df)\n",
    "    df_heatmap.loc[cat_B, cat_A] = len(sub_df)\n",
    "#     print(cat_A, cat_B, len(sub_df))\n",
    "\n",
    "sns.heatmap(df_heatmap , annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type_A, type_B = 'fibro_A2', 'fibro_A3'\n",
    "\n",
    "df_masked_fibros[((df_masked_fibros['pair_A'] == type_A) & (df_masked_fibros['pair_B'] == type_B)) | \n",
    "          ((df_masked_fibros['pair_A'] == type_B) & (df_masked_fibros['pair_B'] == type_A))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting information between fibroblasts and other cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Processing \n",
    "\n",
    "df_processed = df_unstack\n",
    "%store -r dict_knee_markers\n",
    "\n",
    "# 1) Remove duplicates by all columns expect value. This is because if pair_A == pair_B in some cases the values are the same. \n",
    "# This produces problems later when counting datasets.\n",
    "\n",
    "pair_gene_cols = ['gene_A', 'gene_B', 'pair_A', 'pair_B']\n",
    "\n",
    "df_processed = df_processed.groupby(['dataset'] + pair_gene_cols, as_index=False).mean()\n",
    "\n",
    "\n",
    "\n",
    "# 2) We group the values. For the numeric values, we compute the median across cases. For string values, we join and count them. \n",
    "\n",
    "df_grouped = pd.DataFrame(index=df_processed.groupby(pair_gene_cols).sum().index)\n",
    "df_grouped['value'] = df_processed.groupby(pair_gene_cols).median()['value']\n",
    "df_grouped['dataset_list'] = df_processed.groupby(pair_gene_cols)['dataset'].apply(', '.join)\n",
    "df_grouped['dataset_count'] = df_processed.groupby(pair_gene_cols)['dataset'].count()\n",
    "df_grouped = df_grouped.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# 3) We want to keep only the LR pairs that are consistentr among datasets. Therefore, we will establish a threshold of datasets in which \n",
    "# that interaction appears. Because some clusters are specific of fewer datasets, we will consider the lower threshold a percentage (60-80%) of\n",
    "# the less frequent cluster\n",
    "\n",
    "# 3A) Create the dict with correspondence between clusters and counts\n",
    "list_clusters = []\n",
    "for adata in list_adatas_fb:\n",
    "    list_clusters += adata.obs['cluster_robust'].cat.categories.tolist()\n",
    "clusters, counts = np.unique(list_clusters, return_counts=True)\n",
    "dict_cluster_counts = dict(zip(clusters, counts))\n",
    "\n",
    "# 3B) Apply the dataset filter\n",
    "thres = 0.5\n",
    "\n",
    "pair_A_counts = [dict_cluster_counts[i[-2:]] if i[-2:] in dict_cluster_counts.keys() else 100 for i in df_grouped['pair_A'].values]\n",
    "pair_B_counts = [dict_cluster_counts[i[-2:]] if i[-2:] in dict_cluster_counts.keys() else 100 for i in df_grouped['pair_B'].values]\n",
    "min_pair_counts = [min(i, j) for i, j in zip(pair_A_counts, pair_B_counts)]\n",
    "\n",
    "mask_idx = df_grouped['dataset_count'] > np.array(min_pair_counts) * thres\n",
    "\n",
    "\n",
    "df_grouped = df_grouped.replace('nan', np.nan)\n",
    "df_masked = df_grouped.loc[mask_idx].dropna(subset=['gene_A', 'gene_B'], how='all').reset_index(drop=True)\n",
    "\n",
    "# 3C) Apply the gene filter: we are going to keep genes that are \"relevant\" markers. Other genes that appear as positive in CellPhoneDB tend to \n",
    "# be thorougly expressed and are not relevant\n",
    "pair_A_bool = [((pair_A[-2:] in dict_knee_markers.keys()) & (pair_B[-2:] not in dict_knee_markers.keys()) & \n",
    "                (gene_A in dict_knee_markers.get(pair_A[-2:], []))) \n",
    "                 for gene_A, pair_A, pair_B in zip(df_masked['gene_A'].values, df_masked['pair_A'].values, df_masked['pair_B'].values)]\n",
    "pair_B_bool = [((pair_B[-2:] in dict_knee_markers.keys()) & (pair_A[-2:] not in dict_knee_markers.keys()) & \n",
    "                (gene_B in dict_knee_markers.get(pair_B[-2:], []))) \n",
    "                 for gene_B, pair_B, pair_A in zip(df_masked['gene_B'].values, df_masked['pair_B'].values, df_masked['pair_A'].values)]\n",
    "\n",
    "mask_bool = np.array(pair_A_bool) != np.array(pair_B_bool)\n",
    "# mask_bool = mask_bool == 1\n",
    "\n",
    "df_masked = df_masked.loc[mask_bool].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "df_alias = df_masked.copy()\n",
    "cats_nofibro = [i for i in sorted(list(set(df_alias['pair_A']) | set(df_alias['pair_B']))) if 'fibro' not in i ]\n",
    "cats_fibro = [i for i in sorted(list(set(df_alias['pair_A']) | set(df_alias['pair_B']))) if 'fibro' in i ]\n",
    "df_heatmap = pd.DataFrame(0, index=cats_fibro, columns=cats_nofibro)\n",
    "\n",
    "\n",
    "for cat_A, cat_B in itl.product(cats_nofibro, cats_fibro):\n",
    "    sub_df = df_alias[((df_alias['pair_A'] == cat_A) & (df_alias['pair_B'] == cat_B)) | \n",
    "                      ((df_alias['pair_A'] == cat_B) & (df_alias['pair_B'] == cat_A))].drop_duplicates(['gene_A', 'gene_B'])\n",
    "    if 'fibro' in cat_B:\n",
    "        cat_A, cat_B = cat_B, cat_A\n",
    "    df_heatmap.loc[cat_A, cat_B] = len(sub_df)\n",
    "\n",
    "sns.heatmap(df_heatmap.iloc[:-1], annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type_A, type_B = 'fibro_D1', 'peri - CYCS'\n",
    "\n",
    "df_masked[((df_masked['pair_A'] == type_A) & (df_masked['pair_B'] == type_B)) | \n",
    "          ((df_masked['pair_A'] == type_B) & (df_masked['pair_B'] == type_A))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual curation\n",
    "\n",
    "Although these list are interesting and have been fioltered from many spurious interactions, they need further improvement. To do that, We have selected the L-R pairs, regardless of cluster, and assigned the clusters manually, so that we account for all possible interactions. This curated list is available at [this link](https://docs.google.com/spreadsheets/d/1lfI6sgjEyg37BGL7VRMfW7KgwGKwX5QrCtnKYk1DXY4/edit?usp=sharing)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:triku-notebooks]",
   "language": "python",
   "name": "conda-env-triku-notebooks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
